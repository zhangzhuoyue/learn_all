### redis

---
### 关系型数据库和非关系型数据库区别  
1. [区别](https://www.cnblogs.com/sunzhiqi/p/10869655.html)  
    1. 存储方式  
       ```
       1. 关系型数据库是表格式的，因此存储在表的行和列中。他们之间很容易关联协作存储，提取数据很方便。
       2. 系模型就是“一对一、一对多、多对多”等关系模型，关系模型就是指二维表格模型,因而一个关系型数据库就是由二维表及其之间的联系组成的一个数据组织。
       
       3. Nosql数据库则与其相反，他是大块的组合在一起。通常存储在数据集中，就像文档、键值对或者图结构。
       4. 非关系型模型比如有:
              1.列模型：存储的数据是一列列的。关系型数据库以一行作为一个记录，列模型数据库以一列为一个记录。（这种模型，数据即索引，IO很快，主要是一些分布式数据库）
              2.键值对模型：存储的数据是一个个“键值对”，比如name:liming,那么name这个键里面存的值就是liming;  redis,MemcacheDB
              3.文档类模型：以一个个文档来存储数据，有点类似“键值对”。; mongdb
      
       ```
       
    2. 存储结构  
        ```
       1. 关系型数据库对应的是结构化数据，数据表都预先定义了结构（列的定义），结构描述了数据的形式和内容。这一点对数据建模至关重要，虽然预定义结构带来了可靠性和稳定性，但是修改这些数据比较困难。
       2. Nosql数据库基于动态结构，使用与非结构化数据。因为Nosql数据库是动态结构，可以很容易适应数据类型和结构的变化。
         
       ```
        
    3. 存储扩展  
        ```
       1. 这可能是两者之间最大的区别，关系型数据库是纵向扩展，也就是说想要提高处理能力，要使用速度更快的计算机。因为数据存储在关系表中，操作的性能瓶颈可能涉及到多个表，需要通过提升计算机性能来克服。虽然有很大的扩展空间，但是最终会达到纵向扩展的上限。
       2. Nosql数据库是横向扩展的，它的存储天然就是分布式的，可以通过给资源池添加更多的普通数据库服务器来分担负载。
       ```
2. 优势 劣势  
   1. 关系型数据库  
      ```
      优势
      1.容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解
      2.使用方便：通用的SQL语言使得操作关系型数据库非常方便
      
      
      劣势
      1.在频繁的读写，对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
      2.对于关系型数据库来说，在一张包含海量数据的表中查询，效率是非常低的
      3.数据扩展不方便
      ```
   2. 非关系型数据库  
      ```
      优势：
      1.用户可以根据需要去添加自己需要的字段，为了获取用户的不同信息，不像关系型数据库中，要对多表进行关联查询。仅需要根据id取出相应的value就可以完成查询。
      2.非关系型数据库一般在内存中工作，读写快
      
      劣势：
      只适合存储一些较为简单的数据，对于需要进行较复杂查询的数据，关系型数据库显的更为合适。不适合持久存储海量数据
      ```
---
### redis基本数据结构
1. String  
   ```
   1. 一个Key对应一个Value，string类型是二进制安全的。
   2. Redis的string可以存储任何数据，比如jpg图片(生成二进制)或者序列化的对象。
   3. 最常用的数据的数据类型
   4. string类型的应用场景时有所介绍，string + json也是存储对象的一种方式，那么存储对象时，到底用string + json还是用hash呢？
   
   5. 如果存储的value是对象需要进行序列化；如果是基本数据类型转换为String存储
   ```

2. Hash(Key-Value)  
   ```
   1. hash是一个string 类型的field和value的映射表
   2. 需要三个元素  ：唯一ID ，field ,value;hash类型的(key, field, value)的结构与对象的(对象id, 属性, 值)的结构相似，也可以用来存储对象
   3. key—field—value的方式。一个key可对应多个field，一个field对应一个value
   ```
3. [hash和string都可以进行序列化，如何选择？](https://www.cnblogs.com/pangzizhe/p/10657801.html)  
   ```
    	string + json	hash
   效率	    很高	     高
   容量	    低	         低
   灵活性   低	         高
   序列化	简单     	复杂
   1. 某个属性需要频繁修改时，不适合用string+json，因为它不够灵活，每次修改都需要重新将整个对象序列化并赋值，如果使用hash类型，则可以针对某个属性单独修改，没有序列化，也不需要修改整个对象
   2. 当对象的某个属性不是基本类型或字符串时，使用hash类型就必须手动进行复杂序列化
   ```
4. List  
   ```
   1. list是一个链表结构，主要功能是push, pop, 获取一个范围的所有的值等。操作中key理解为链表名字。
   2. Redis的list类型其实就是一个每个子元素都是string类型的双向链表。我们可以通过push,pop操作从链表的头部或者尾部添加删除元素，这样list既可以作为栈，又可以作为队列
   3. 可以有序消费
   ```

5. Set  
   ```
   1. 是string类型的无序集合。set是通过hash table实现的，可以进行添加、删除和查找。对集合我们可以取并集，交集，差集.
   2. 集合可以进行 交集、并集 如新浪微博中获取两个用户共同的关注人
   3. 
   ```

6. zset  
   ```
   1. 有序不重复；sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。
   2. 一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构
   3. 是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。
      
      zset的成员是唯一的,但分数(score)却可以重复。
   ```
7. [对象序列化](https://blog.csdn.net/yangstarss/article/details/79568270)  
   ```
    1. 对象实现序列化serializable 
    2. 序列化：1.将数据输出到redis，使用输出流；作用目标是对象，需要对象输出流ObjectOutputStream，最终结果是二进制流，需要一个字节输出流ByteArrayOutputStream
              2. 将字节输出流作为参数传递对象输出流；
              3. 将对象写入到对象输出流中，然后toByteArray()获取对象的字节数组
   public class SerializeUtil {
       /*
        * 序列化
        * */
       public static byte[] serizlize(Object object){
           ObjectOutputStream oos = null;
           ByteArrayOutputStream baos = null;
           try {
               baos = new ByteArrayOutputStream();
               oos = new ObjectOutputStream(baos);
               oos.writeObject(object);
               byte[] bytes = baos.toByteArray();
               return bytes;
           } catch (Exception e) {
               e.printStackTrace();
           }finally {
               try {
                   if(baos != null){
                       baos.close();
                   }
                   if (oos != null) {
                       oos.close();
                   }
               } catch (Exception e2) {
                   e2.printStackTrace();
               }
           }
           return null;
       }
       /*
        * 反序列化
        * */
      1. 将数据读入到内存中，使用输入流。对象输入流和字节输入流。
      2. 字节输入流读取字节对象，然后借助对象readObject方法获取对象方法。
       public static Object deserialize(byte[] bytes){
           ByteArrayInputStream bais = null;
           ObjectInputStream ois = null; 
           try{
               bais = new ByteArrayInputStream(bytes);
               ois = new ObjectInputStream(bais);
               return ois.readObject();
           }catch(Exception e){
               e.printStackTrace();
           }finally {
               try {
    
               } catch (Exception e2) {
                   e2.printStackTrace();
               }
           }
           return null;
       }
   }
   ```

---
### redis集群演变  
1. 单机版 ：实现高可用的核心是持久化
    ```
    1. 持久化是最简单的高可用方法，主要是做为数据备份，在redis服务宕机，再次启动时，保证数据不会因为进程退出而丢失。
    ```
2. 主从复制  
    ```
    1.主从复制是redis高可用的基础，烧饼模式和集群都是在复制的基础上实现高可用的。复制实现的数据的多样性，将读写分离分流消费。
    2. 缺点：故障无法自动恢复，写操作无法实现负载均衡，
    ```

3. 哨兵  
    ```
    1. 在复制的基础上实现自动化故障恢复
    2. 缺点：写操作无法实现负载均衡；存储能力受到单机限制；在故障恢复期间无法进行对外服务
    3. 有一个redis不存储数据，作为一个监控节点，在主节点宕机情况下，从从节点中选举出一个主节点。历史主节点恢复后为从节点。
    ```

4.  集群  
    1. 集群说明
    ```
    1.  集群搭建：1.使用原生命令  2.使用redis提供的rb脚本 ；redis cluster至少需要三个master节点，每个主节点至少一个slave节点
    2. 集群的关键概念：redis cluster 搭建集群
        
    配置开启clister节点
    1. 配置文件修改 cluster-enabled yes 开启集群模式
    2. cluster-config-file nodes-8001.conf（这里是800X 和poet对应上）
    3.port 4004  指定节点端口号
    4.dir 执行数据存储位置
    5.appendonly yes  集群的高可用是以主从复制为基础的。
    
    meet
    1. cluster meet ip port 
    
    指派槽
    1.查看crc16算法算出key的槽位命令 cluster keyslot key 
    默认平均分配槽位。在存储数据时，计算key的槽数，获取对应的接节点的连接。
    
    分配主从
    cluster replicate node-id
    ```
    2. 集群说明2
    ```
    redis cluster的原理：
    1.Redis Cluster是去中心化的没有代理，所以只能通过客户端分片，它分片的槽数有16384个，槽和节点的映射关系保存在每个节点上，每个节点每秒钟会ping十次其他几个最久没通信的节点，其他节点也是一样的原理
    互相PING ，PING的时候一个是判断其他节点有没有问题，另一个是顺便交换一下当前集群的节点信息、包括槽与节点映射的关系等。客户端操作key的时候先通过分片算法算出所属的槽，然后随机找一个服务端请求。
    
    2.但是可能这个槽并不归随机找的这个节点管，节点如果发现不归自己管，就会返回一个MOVED ERROR通知，引导客户端去正确的节点访问，这个时候客户端就会去正确的节点操作数据。
    
    3.集群状态下的注意事项：
    多键操作不支持（如mset k1 v1 k2 v2;k1,k2可能不在一个服务器上）
    由于多键操作不支持直接导致redis事物不支持
    
    4.redis cluster 原理解说
    reids cluster模式最小得6个服务，每个服务之间通过ping-pong机制实现相互感知（注意：此模式没有单独的哨兵监控，集群内部完全自制）。redis集群数据存储类似于hashmap，
    其将数据划成16484个片区（又叫插槽，每个槽可以放n多个数据），通过对key进行一定的算法与16384取模，得到其在16384中间的一个片区中。如上图姑且认为1-4；2-5；3-6，两两结对，
    前者为master负责写（其实也具备读能力），后者slave负责读，而且是只读，防止数据出现不一致,同时slave从master同步数据。按照上述配对，1-4主从将只负责0-5500片区的读写；
    2~5主从只负责5501-11000片区的读写;3-6主从负责11001-16383片区的读写，从而实现了分摊了读写的压力。
    
    5.去中心化，实现集群自制。
    
    6.可以使用监控工具检测
    Prometheus+Grafana
    1.Prometheus基本原理是通过HTTP协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供HTTP接口就可以接入监控系统，适合Docker、Kubernetes环境的监控系统之一
    2.输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，可以查看磁盘、内存、CPU等信息
    3.不依赖分布式存储，单个服务器节点。
    
    Grafana
    grafana是用于可视化大型测量数据的开源程序
    grafana有热插拔控制面板和可扩展的数据源，目前已经支持Graphite、InfluxDB、OpenTSDB、Elasticsearch等。
    ```

5. 集群中需要注意的点
    ```
    cluster中的命令查找  /usr/local/bin/redis-cli  --cluster help
    1. 主从节点具有故障恢复功能，在节点恢复期间该节点不对外提供服务，会造成数据的部分丢失
    2. 每个主节点都会分配对应的槽数 0-16383 ，为什么不是65536；如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大
    3.  在进行缩容和扩容，重新计算每个节点的槽数，数据也会自动迁移。
   
   4. java如何使用redis集群  
      lettuce 客户端RedisClusterClient
       1.程序中指定 ip port
       2. redisClusterClient :传递的地址可能很多，但是有一个可用就可以。
       3. 连接上后，执行cluster nodes获取映射关系，并保存早本地
       4. 为每一个节点创建一个连接池GenericObjectPool 
       5. 如果执行写入操作，本地首先根据映射关系，知道应该发送的节点【计算key的hash值，然后根据每个节点的槽数范围确定连接哪一个节点】
       6. 如果失败，则进行重定向错误，重新获取映射关系，重新进行一次写操作。
    ```
7.  缓存穿透  数据库和缓存中都没有这条数据
[使用布隆过滤器的流程图](https://img-blog.csdnimg.cn/20181209154238238.png)
   ```
   问题总述：缓存是数据库数据的子集，数据库不存在，缓存一定不存在。导致缓存失效，直接访问数据库，给数据库造成压力
   注意：缓存穿透是不可避免的，所做的是减少缓存未命中情况下的数据库访问
   在访问量不大的情况，穿透是可以容忍的。在访问量比较大是需要解决该问题
   场景一、
   固定的访问少量数据，但是数据库没有数据，导致的缓存穿透；这种解决将从数据库查询的null放在redis中，并设置过期时间
   
   场景二、
   随机访问的数据，但是数据库中不存在，导致缓存穿透；解决方案：布隆过滤器
   
   布隆过滤器：
   
   1.介绍：
   位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。
   Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合(false positive)。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省
   ————————————————
   版权声明：本文为CSDN博主「程序员历小冰」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
   原文链接：https://blog.csdn.net/u012422440/article/details/94088166
   
   
   2.使用流程：
   当业务系统有查询请求的时候，首先去BloomFilter中查询该key是否存在。若不存在，则说明数据库中也不存在该数据，因此缓存都不要查了，直接返回null。
   若存在，则继续执行后续的流程，先前往缓存中查询，缓存中没有的话再前往数据库中的查询。
   
   3.布隆过滤器原理简析：
           简化理解：将查询条件放在内存中，每次查询数据库时到map中查询是否存在，同时查询条件多种多样，导致内存占用过大，反而降低匹配效率
           布隆过滤器要素：数据量，错误率，存储标识数组大小
           1. 一个模糊匹配，存在一定的错误率【自定义】，容忍一定的错误换区较低的内存使用。
           2. 预先将需要过滤的条件计算hash值，然后取模获取数组下标，在下标元素给出true标识。他的错误率：hash存在hash碰撞，存在标识可能数据不存在，不存在标识数据一定不存在。
           3. 在查询时根据查询条件计算出hash值，对比数组中是否有该元素标识。如果不存在则拒绝访问数据库。
   
   降低错误率：增加数组的容量，适当增加hash函数。怎么增加：
   数组大小：m = - n *n*fpp/(ln2)^2    n 数据量    fpp错误率：集合里没有某元素，查找结果是有该元素
   hash函数个数：k = m/n * ln2    每个函数函数都会生成一个标识，如果在查询时有一个hash不符合，则该元素不存在。
   
   
   
   ```

8. 缓存雪崩  
   ```
   本质是宕机问题，两个思路：
   1. 使用集群 cluster
   2. 过期时间错开
   
   ```

9. 缓存击穿   数据库中有这条数据，缓存中没有数据(并发)
    ```
    1.  导致直接查询数据库。
    2. 使用互斥锁解决问题，使用redis锁的分布式所锁，全局锁，可以限制不同服务的访问
    3. setnx 设置k-v ，如果value已经存在返回0 ，表示设置失败。如果value不存在，返回1，表示设置成功；  expire 设置过期时间，超时造成的死锁。
    
   ```

10. 缓存更新一致性问题 ：B站收藏视频
    1. 先更新数据库，再更新缓存 弊端
   ```
   问题1：单线程下修改数据库，然后更新缓存
    1. 更新数据库
    2. 跟新缓存失败
   导致问题：数据库中是新的数据，缓存中是旧的数据，数据出现不一致问题
   
   问题2：多线情况下，修改同一条数据，然后更新缓存
   1.线程A跟新数据库数据，然后更新缓存
   2.线程B更新数据库，然后更新缓存
   导致问题：如果因为网络问题，B比A更早的更新了缓存，导致脏数据（数据不一致）
   解决方案：先删除缓存数据，然后更新数据库。那么数据库中是旧数据，缓存中为空，那么数据不会不一致。因为缓存中没有数据，会向数据数据库中读取旧数据，更新到缓存
   ```
   2. 先删除缓存，再跟新数据 弊端  
   ```
   1. 线程A首先删除缓存数据
   2. 线程B查询缓存，发现缓存为空，查询数据库，并将数据插入缓存中
   3. 线程A 在线程B执行完之后，开始执行数据库更新
   导致问题：首先删除缓存，然后更新数据库。此时还没来得及更新数据库。这是一个请求查询缓存，发现为空，则查询数据库，将数据插入到缓存中。随后数据库更新完成。此时数据库和缓存数据不一致。
   ```

   3. 解决数据库和缓存不一致问题：方案一 延时方案
   ```
   1. 缓存的删除操作：线程 A 首先删除缓存，然后更新数据库
   2. 缓存的读操作：线程 B 查询缓存为空，则查询数据库，然后将数据加入到缓存。
   3. 数据库更新，再缓存更新：线程A更新完数据库后，再次删除缓存中数据。如果在查询请求，则更新缓存数据。
   先删除缓存：一个请求的数据更新操作进行一次数据更新，两次缓存删除操作
   ```
   4. 解决数据库和缓存不一致问题：方案二 ：[提供一个保障的重试机制即可，这里给出两套方案。](https://blog.csdn.net/xlgen157387/article/details/80389101)
    ```
   
     （1）更新数据库数据；
     
     （2）缓存因为种种问题删除失败；
     
     （3）将需要删除的key发送至消息队列；
     
     （4）自己消费消息，获得需要删除的key；
     
     （5）继续重试删除操作，直到成功；
   
    ```
---
### 缓存数据更新，使用定时任务
    ```
    使用定时任务
    ```
---
### 持久化  
* RDB  
      ```
      1.RDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发
      2.RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。由于每次生成RDB开销较大，无法做到实时持久化，一般用于数据冷备和复制传输。
      3.Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的
      ```
      
   手动触发 自动触发
    ```
    手动触发分别对应save和bgsave命令
      ·save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用
      ·bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短
      
      2.自动触发RDB的持久
      1）使用save相关配置，如“save m n”。表示m秒内数据集存在n次修改 时，自动触发bgsave。
    
      2）如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点，更多细节见6.3节介绍的复制原理。
    
      4）默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则 自动执行bgsave。
    
      bgsave是主流的触发RDB持久化方式
    	1）执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进 程，如RDB/AOF子进程，如果存在bgsave命令直接返回。
    
       2)在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令 ），
       操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据
       
    
    RDB文件的处理
    
    保存：RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配 置指定。可以通过执行config set dir{newDir}和config set dbfilename{newFileName}运行期动态执行，当下次运行时RDB文件会保存到新目录。
    ```
    RDB的优缺点
    ```
    RDB的优点：
    ·RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据 快照。非常适用于备份，全量复制等场景。比如每6小时执行bgsave备份， 并把RDB文件拷贝到远程机器或者文件系统中（如hdfs），用于灾难恢复。
    
    ·Redis加载RDB恢复数据远远快于AOF的方式。
    
    RDB的缺点：
    ·RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运 行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高。
    
    ·RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式 的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。
    
    针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化
    ```
* AOF
    ```
       1.AOF特点
       1.AOF的主要作用 是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式
       2.AOF通过追加写命令到文件实现持久化,因为需要不断追加写命令，所以AOF文件体积逐渐变大，需要定期执行重写操作来降低文件体积。
       
       
       2.AOF的使用
       默认情况下Redis没有开启AOF(append only file)方式的持久化，可以在redis.conf中通过appendonly参数开启：appendonly yes
       AOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写（rewrite）、重启加载 （load）
       
       
       3.AOF文件名
       开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：
       appendfilename appendonly.aof
     ```
    AOF重写  
     ```
     3.AOF的重写
     配置redis自动重写AOF文件的条件
      
     auto-aof-rewrite-percentage 100  # 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据
      
     auto-aof-rewrite-min-size 64mb   # 允许重写的最小AOF文件大小
     配置写入AOF文件后，要求系统刷新硬盘缓存的机制
      
     # appendfsync always   # 每次执行写入都会执行同步，最安全也最慢
     appendfsync everysec   # 每秒执行一次同步操作
     
     # appendfsync no       # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），最快也最不安全
      
     Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少
     

     随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。
     重写后的AOF文件为什么可以变小？有如下原因：
     
     1）进程内已经超时的数据不再写入文件。
     
     2）旧的AOF文件含有无效命令，如del key1、hdel key2、srem keys、set a111、set a222等。重写使用进程内数据直接生成，这样新的AOF文件只保
     
      留最终数据的写入命令。
     
     3）多条写命令可以合并为一个，如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢 出，对于list、set、hash、zset等类型操作，以64个元素为界拆分为多条。
     
     AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF 文件可以更快地被Redis加载
    ```
    3.redis重启，加载持久化数据  
    ```
    流程说明：
    
    1）AOF持久化开启且存在AOF文件时，优先加载AOF文件，打印如下日志：
    
    * DB loaded from append only file: 5.841 seconds
    
    2）AOF关闭或者AOF文件不存在时，加载RDB文件，打印如下日志：
    
    * DB loaded from disk: 5.586 seconds
    
    3）加载AOF/RDB文件成功后，Redis启动成功。
    
    4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。
    ```
---
### 淘汰策略
     ```
    redis采用的是定期删除+惰性删除策略。
    为什么不用定时删除策略?
    定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.
    定期删除+惰性删除是如何工作的呢?
    定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。
    于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。
    
    采用定期删除+惰性删除就没其他问题了么?
    不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。
    redis.conf中有一行配置
    maxmemory-policy volatile-lru
    该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)
    volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
     ```
---
### 主从复制  
* Redis的主从复制原理总述 
   ```
    1. Redis虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis支持主从复制，Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步
    ```
   2. 全量同步  
   ```
   全量同步
   Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 
   -  从服务器连接主服务器，发送SYNC命令； 
   -  主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
   -  主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
   -  从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
   -  主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
   -  从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；
   ```
   3. 增量同步  
   ```
   Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 
   增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令

   ```
---
### 主从复制策略  
* 总述 
    ```
    主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。
    ```
* 配置  
   ```
     配置
     1.主从复制的配置十分简单：把下面这行加入到从服务器的配置文件中即可。
     slaveof 192.168.1.1 6379
      
     2.当然你需要把其中的192.168.1.1 6379替换为你自己的主服务器IP（或者主机名hostname）和端口。另外你可以调用SLAVEOF命令，
     主服务器就会开始与从服务器同步。
      
     关于部分重新同步，还有一些针对复制内存缓冲区的优化参数。查看Redis介质中的Redis.conf示例获得更多信息。
      
     使用repl-diskless-sync配置参数来启动无磁盘复制。使用repl-diskless-sync-delay 参数来配置传输开始的延迟时间，以便等待
     更多的从服务器连接上来。查看Redis介质中的Redis.conf示例获得更多信息。
   ```
* 从机只读服务器  
     ```
     从Redis 2.6开始，从服务器支持只读模式，并且是默认模式。这个行为是由Redis.conf文件中的slave-read-only 参数控制的，
     可以在运行中通过CONFIG SET来启用或者禁用。
      
     只读的从服务器会拒绝所有写命令，所以对从服务器不会有误写操作。但这不表示可以把从服务器实例暴露在危险的网络环境下，
     因为像DEBUG或者CONFIG这样的管理命令还是可以运行的。不过你可以通过使用rename-command命令来为这些命令改名来增加安全性。
      
     你可能想知道为什么只读限制还可以被还原，使得从服务器还可以进行写操作。虽然当主从服务器进行重新同步或者从服务器重启后，
     这些写操作都会失效，还是有一些使用场景会想从服务器中写入临时数据的，但将来这个特性可能会被去掉。
    ```
---
### 集群模式下事务功能鸡肋  
      ```
      同时有多个子系统去set一个key。这个时候要注意什么呢？ 不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片
      操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。
      ```
---
### redis单线程好处：实现分布式锁基础  
    ```
     (1)如果对这个key操作，不要求顺序： 准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可
     
     (2)如果对这个key操作，要求顺序： 分布式锁+时间戳。 假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，
       发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。
     
     (3) 利用队列，将set方法变成串行访问也可以redis遇到高并发，如果保证读写key的一致性
     对redis的操作都是具有原子性的,是线程安全的操作,你不用考虑并发问题,redis内部已经帮你处理好并发的问题了。
    ```
---
###  基于redis实现分布式锁  
    ```
    原理
    Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。
    将 key 的值设为 value ，当且仅当 key 不存在。 若给定的 key 已经存在，则 SETNX 不做任何动作
    
    解锁：使用 del key 命令就能释放锁
    解决死锁：
    1）通过Redis中expire()给锁设定最大持有时间，如果超过，则Redis来帮我们释放锁。
    2） 使用 setnx key “当前系统时间+锁持有的时间”和getset key “当前系统时间+锁持有的时间”组合的命令就可以实现。
    
    
    代码实现
    二.具体的使用步骤如下：
         1. setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁，转向2。
         2. get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向3。
         3. 计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime。
         4. 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。
         5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。
    实现分布式锁，需要结合java进程锁，实现等待-通知机制实现重试，当这个全局锁释放后通知当前线程进行元素操作。
    具体代码实现参考：
    原文链接：https://blog.csdn.net/abbc7758521/article/details/77990048
   ```
---
### 基于布隆过滤器的面试题
* 两个大文件 ，但是服务器内存之后4G，如果模糊的匹配出交集
```
1. 将文件1 读取到内存中，计算每条数据的hash值，根据hash%byte数组容量，在下标元素做出标识。
2. 强文件2 读取到内存，计算每条数据的hash值，根据hash%byte数组容量，判断下标元素有值，则该元素是交集，否则不是
```
* 精确匹配两个大文件中的交集
```
1. 首先将两个文件分成1000份，计算每条数据的hash，将hash%1000,将结果相同的数据放到同一条文件中，并且文件名为hash%1000
2. 比较文件名相同文件，得出交集
```



















































