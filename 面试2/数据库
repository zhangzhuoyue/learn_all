### mysql函数使用那些  

1. 

--- 
### mysql如何拼接查询条件   mybatis如何like预处理 
1. 

---
### 防止sql注入的方式  

1. 使用预编译 
2. 使用正则表达式

--- 
### sql优化
* 索引的结构分析  

* 如何使用上索引  

* Explain 分析查询语句时候使用索引  

* 表的关联查询角度：小表驱动大表

--- 

### MySQL引擎分析  

* Innodb myism的不同  

* 两个引擎的支持的锁不同

---
### 聚簇索引   非聚簇索引 
* 分析区别 

---
### 存储过程  

* 解决了什么问题  
---
### 维护数据库的完整性和一致性，用约束、触发器还是自写业务逻辑？  

？  

--- 
### 事务属性  数据库的特性 
* ACID

---
### 事务 

---
### sql中空值的比较  

---
### [手写jdbc图片](https://www.cnblogs.com/ysource/p/10216115.html)

---
### 分库分表的id处理
1. 面试官心理分析  
    ```
   其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个全局唯一的 id 来支持，排序问题等。所以这都是你实际生产环境中必须考虑的问题。
   ```

2. 数据库自增 id
    ```
   数据库自增 id
   这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。
   
   这个方案的好处就是方便简单，谁都会用；缺点就是单库生成自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是无论如何都是基于单个数据库。
   
   适合的场景：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你并发不高，但是数据量太大导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。
   ```


## 数据库

### mysql

##### Mysql的架构
*  mysql分为server层和存储引擎

      server层
      * 连接器：管理连接权限验证
      * 查询缓存： 命中缓存直接换回查询结果
      * 分析器： 分析语法
      * 优化器： 生成执行计划，选择索引
      * 执行器： 操作索引返回结果

      存储引擎
        存储引擎负责数据的存储和提取，其架构是插件式，innodb sql 5.5.5版本开始成为mysql的默认存储引擎。

      各种引擎的对比：  
        1  innoDB ：支持事务，支持外键，InnoDB是聚焦索引，数据文件是和索引绑在一起的。必须要有主键，通过主键索引效率很高，但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据，不支持全文检索。  
        2.  MyISAM: 不支持事务，不支持外键，MySAM是非聚焦索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的，查询效率上MyiSAM要高于InnoDB,因此做读写分离的时候一般选择用InnoDB做主机，MYISAM做从机。  
        3. Menmory: 有比较大的缺陷使用场景很少，文件数据都存储在内存中，如果mysqld 的进程发生异常，重启或者关闭机器数据就会消失。  

      sql的执行过程

        第一步： 客户端连接上mysql数据库的连接器，连接器获取权限，维持管理连接；连接完成后如果你没有后续的指令这个连接就会处于空闲状态，如果太长时间不使用这个连接就会断开，这个空闲时间默认为8小时，由wait_timeout参数控制。

        第二步： 往mysql数据库发送一条sql,这个时候查询缓存开始工作，看看之前有没有执行过这个sql,如果有则直接返回缓存里的数据到客户端，只要对表执行过更新错作缓存都会失效，因此一些很少更新的数据表可考虑使用数据缓存，对频繁更新的表使用缓存反而弊大于利。使用缓存的方法如下sql,通过SQL_CACHE指定：
            select SQL_CACHE * from table  where xxx=xxx

        第三步： 当未命中缓存的时候，分析器开始工作，分析器判断你是select 还是update 还是insert ，分析你的语法是否正确

        第四步： 优化器根据你的表的索引和sql语句决定使用哪个索引，决定join的顺序

        第五步： 执行器执行sql ,调用存储引擎的接口，扫描遍历表或者插入更新数据。

#### Mysql 索引
  索引介绍：
  
      索引按数据结构可分为哈希表、有序数组、搜索树、跳表。
        * 哈希表适用于只有等值查询的场景。
        * 有序数组适合等值查询和范围查询的场景，但有序数组的索引的更新代价大，所以最好用于静态数据表。
        * 搜索树的搜索效率稳定，不会出现大幅波动，而且基于索引的顺序扫描时，也可以利用双向指针快速左右移动，效率非常高。
        * 跳表可以理解为优化的哈希索引。

      innodb 使用了B+ 数索引模型，而且是多叉树，虽然二叉树的是索引中效率最高的，但是索引需要写入磁盘，如果使用二叉树磁盘IO会变得很频繁。在innodb索引中分为主键索引（聚簇索引）和非主键索引（二级索引）。主键索引保存了该行数据的全部信息，二级索引保存了该行数据的主键；所以使用二级索引的时候会先查询出主键值，然后回表查询出数据。而使用主键索引则不需要回表。

      对二级索引而言可使用覆盖索引来优化sql,看下面的两条sql
      select * from  table where key =1;select id form table wehere key=1;

      key 是一个二级索引，第一条sql是先查出id,然后根据id 回表查询出真正的数据。而第二条数据查询索引后直接返回数据不需要回表。第二条sql索引key覆盖了我们的查询需求，称为覆盖索引。
      叶子节点存储索引，B+tree 的树高度较低
      单次请求涉及的磁盘IO次数少（出度d大，且非叶子节点不包含表数据，树的高度小）；
      查询效率稳定（任何关键字的查询必须走从根结点到叶子结点，查询路径长度相同）；
      遍历效率高（从符合条件的某个叶子节点开始遍历即可）
      二叉树：
             遍历二叉树
             前序遍历  先访问根结点,然后前序遍历左子树,再前序遍历右子树
             中序遍历0  中序遍历根结点的左子树,然后是访问根结点,最后遍历右子树
             后序遍历0  从左到右先叶子后结点的方式遍历访问左右子树,最后访问根结点
             层序遍历日  从根结点从上往下逐层遍历,在同一层,按从左到右的顺序对结点逐个访问
      
      
      
      普通索引和唯一索引
          innodb是按数据也来读取数据的，当要读取一条数据时候是先将本页数据全部读到内存中，然后找到对应的数据，而不是直接读取，每页数据的默认大小为16KB.
          当一个数据页需要更新数据时，如果内存中有该数据页就直接更新，如果没有该数据页则在不影响数据一致性的前提下；更新操作先缓存到change buffer中，在下次查询需要访问这个数据页的时候再写入更新操作除了查询会将 change buffer 写入磁盘，后台线程也会定期将change buffer 写入磁盘。对于唯一索引来说所有的更新操作都要先判断这个操作是否为违反唯一性的约束，因此唯一索引的更新无法使用change buffer ,而普通索引则可以。唯一索引比普通索引更新多一个唯一性校验的过程。

      联合索引
          两个或者更多列上的索引被称为联合索引（或者符合索引）。联合索引可以减少索引的开销，以联合索引（a,b,c）为例子，建立这样的索引箱单余建立了索引 a,ab,abc三个索引，————mysql 从左到右的使用索引中的字段，一个查询可以只使用索引的一部分，但是只能是最左侧的部分，而且最左侧字段是常量引用时，索引就十分有效，这就是最左前缀原则。由最左前缀原则可知，组合索引是有顺序的，那么哪个索引放在最前面就比较有讲究，对于组合索引还有一个知识点
              索引下推，假设组合索引（a,b,c）如下sql，
                select * form  table where a=xxx and b = xxx
              这个sql 会进行两次筛选，第一次查出 a=xxx数据，再从a=xxx中查出b=xxx数据。使用索引下推和不使用索引下推的区别在于不使用索引下推会先查询出a=xxx 的数据的主键，然后根据查询出的主键回表查询出全部数据，再全数据查询出b=xxx 的数据，而索引下推的执行过程是先查出a=xxx的数据的主键，然后在这些主键上二次查询b=xxx 的主键，然后在回表

                索引下推的特点：
                  * innodb 引擎的表，索引下推只能用于二级索引
                  * 索引下推一般可用于所查询字段不全是联合索引的字段，查询条件为多条件查询且查询字句字段全是联合索引

                
     优化器与索引

      在索引建立之后，一条语句可能会命中多个索引，这是，酒柜交由优化器来选择合适的索引，优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。那么优化器是怎么去确认索引的呢？优化器会优先选择扫描行数最少的索引，同时还会结合使用使用临时表，是否排序等因素经进行综合判断。mysql 在开始执行sql 之前，并不知道满足这个条件的记录有多少个条，而只能根据统计信息来估计，而估计统计信息是通过数据采样得出来的。

      其他索引知识点

        有时候需要索引很长的字符列，这会让索引变得很大很慢还占内存。通常可以开始的部分字符作为索引，这就是前缀索引。这样可以大大节约索引空间，从而提高索引效率，但这样会降低索引的选择性。

      脏页对数据的影响
        当内存数据页和磁盘的数据不一致的时候我们称这个内存页为脏页，内存数据写入磁盘后数据一致，称为干净页。当要读入数据而数据库没有内存的时候，这个时候需要淘汰内存中的数据页——干净页可以直接淘汰掉，而脏页需要先刷入磁盘再淘汰。如果一个查询要淘汰的脏页太多会导致查询的时间变长。为了减少脏页对数据库性能影响，innodb 会控制脏页的比例和脏页刷新时机。


### Mysql 中的锁（表所、行锁）
锁是计算机协调多个进程或者纯线程并发访问某一资源的机制。在数据库表中，除 传统的计算资源（CPU、RAM、I/O）的争用外，数据也是一种供用用户共享的资源，如何保证数据的并发访问的一致性，有效性是所在有数据库必须要解决的的一个问题。锁冲冲突也是影响数据并发访问的性能的一个重要因素，

#### 概述
相对于其他数据库而言，mysql的锁的机制比较复杂，其最显著的特点是不同的存储引擎支持不同的锁机制。mysql可以大致归纳为以下三种：

		1.表级锁：开销小，加锁块，不会出现死锁；锁的粒度比较大，发生锁冲突的概率最高，并发度最低
		2.行级锁：开销大，加锁慢，会出现死锁；锁的粒度小 ，发生锁的冲突的概率最低，并发程度也是最高。
		3.页面锁：开销和加锁的时间介于表锁和行级锁的中间；会出现死锁，锁定粒度介于表锁和行锁之间，并发度一般。

以下是 三种存储引擎 MYISAM 与BDB、InnoDB的各自对行锁、页锁、表锁是否支持

		MYISAM 支持表锁，不支持 行锁与页面锁。
		BDB 支持页面锁，和表锁，不支持行锁。
		InnoDB 支持行锁和表锁，不支持页面锁。 

#### mysql 的存储引擎MYISAM 下表级锁的锁的
mysql的表级锁有两种模式：共享锁（Tabel Read Lock）和表独占锁（Table Write Lock）

		*	对MYISAM的读操作，不会阻塞其他用户对同一张表请求，但会阻塞对同一张表的写请求。
		*	对MYISAM 的写操作，则会阻塞其他用户对同一张表的的读和写操作。
		*	MYIASM 表的读操作和写操作之间，以及写操作之间是串行（注意两种关系）。

当一个线程获得对一个表的写锁之后只有持锁线程可以对表进行更行操作，其他线程的读、写操作都会等待，直到锁被释放为止。

## MYSQL不同存储引擎下的的锁模式介绍

####  1、MYISAM 的模式介绍（因为 MYISAM存储引擎只支持表级锁）
#####  1. 兼容性
	归纳总结：对MYISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一张表的写请求；对MYISAM表的写操作，则会阻塞其他用户对同一张表的的读写之间的请求；MYISAM表的读和写操作之间，以及写和写之间是串行的（当一线程获得对一张表的写锁之后，只有持有锁的线程可以对表进行操作。其他线程的读、写都会等待，直到当前持有锁的线程释放为止。）

#####  2. 如何加锁
MYISAM在执行查询语句时（select ）前，会自动给涉及的所有表加读锁，在执行更新操作（update、delete、insert）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接用 LOCK TABLE 命令给 MYISAM 表添加显式加锁，
给MYISAM表添加显式的锁一般是为了一定程度上模拟事务操作，实现对某一时间点多个表的一致性读取，例如：有一个订单表order ,其中一个还有一个订单明细表order_detail ，其中记录有订单每一个产品的金额小计subtotal,假设我们需要检查这两个表的金额合计是否相等，可能就要执行以下的语句。

	select sum(total) from order;
	select sum(subtotal) from order_detail;

这时，如果不嫌给这两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，order_detail 表已经发生了变化，因此，正确的写法应该是：

	LOCK tables order read local ,order_detail read local;
	select sum(total)from order
	select sum(subtatal) from order_detail
	补充说明：1.上面的例子在LOCK tables 是加了local 选项，其作用，就是在满足MYISAM表的并发插入条件情况下，允许其他用户在表尾插入记录，
	2.在用LOCK tables 给显式加表锁是时，必须同时取得所有涉及表的锁，并且mysql 表并发支持锁升级。也就是说在执行LOCK tables 后，只能访问显式加锁的这些表，不能访问未加锁的表，同时，如果加的锁是读锁，那么只能执行查询操作，而不能执行更新操作。其实在自动加锁的情况下也基本如此，mysql问题一次获得sql语句所需要的全部锁，这也正是MYISAM存储引擎下不会出现死锁的原因，

一个session使用LOCK tables 命令时，给表film_text加了锁，这个session 可以查询锁定表中的记录，但更新或访问其他表都会提示错误；同时，另外一个session 可以查询表中的记录，但更新就会出现锁等待。

##### 并发锁
concurrent_insert和local操作（此操作为MYISAM引擎专有，InnoDB无此功能）
上面说只要给表加了读锁，其他的session对该表的写操作将被阻塞，那么有没有办法让其他session也能往里面添加数据。这里我们可以使用local关键字，语法如下：local table 表名 read local。这样在当前表被加读锁的时候，可以让其他session往表里添加记录，但需要配合concurrent_insert全局变量使用。

在一定条件下，MYISAM页支持查询和操作的并发执行。
MYISAM存储引擎下，有一个系统变量concurent_insert ，专门用以控制其并发插入的行为，其值可以为 0、1、2
*  当concurrent_insert 设置为0 时，不允许并发插入。
*  当concurrent_insert 设置为1时，如果MYISAM 允许在一个读表的同时，另一个机型从表尾插入记录。这也是MYISAM默认的设置。如果表的中间没有被删除的行行为，MYISAM允许在一个进程读表的同时，另一线程从表尾插入记录，这也是myisam的默认设置。

#####  MYISAM的锁的调度
前面讲过，MYISAM 存储引擎的读和写操作是互斥，读操作之间是串行的。那么一个进程请求某个MYISAM表的读锁，通时零一个进程也请求同一张表的写锁，mysql如何处理呢？答案是写进程先获得锁。不仅如此，即使是读操作先获得锁等待的队列，写请求后到，写锁也会查到读请求之前，这是mysql认为写请求比一般的读请求重要。这也是myisam表不太适合用于大量更新操作的和查询操作的应用的原因，因为，大量的更新操作会造成查询操作很难得到锁，从而永远处于阻塞状体。这种情况有时候会变得很槽糕，幸好我们可以通过一些设置来调节MYISAM的调度行为。
		*  通过指定启动low-priority-updates,使得myisam引擎默认给予读请求一优先的权利。
		*  通过执行命令 set LOW_PRIORITY_UPDATES=1,使得连接发出的请求更新请求的优先级降低。
		* 通过指定INSERT、UPDATE、DELETE 语句的LOW_PRIORITY属性，降低语句的优先级。

虽然上面3种方法都是要么更新优先要么查询优先，但是还是可以用来解决查询相对重要的应用中，读锁等待严重的问题。
另外，mysql页提供一种折中的方法，，即给系统参数， max_write_lock_count 设置一个合适的值，当一个表的读锁达到这个值之后，mysql便暂时将写请求的优先级降低。给读进程一定获得锁的机会。

这里还要强调一点：一些需要长时间运行的查询操作，也会是写进程饿死，因此应用中应尽量避免出现长时间运行的查询操作，不要总想用一条select 来解决问题。因为这种看似巧妙的sql语句，往往比较复杂。执行时间较长，在可能的情况下，通过使用中间表等措施随sql 语句做一定的分解，使得每一步查询能在较短时间内完成，从而减少锁冲突，如果负载查询不可避免，应尽量安排在数据库表空闲时间段执行，比如一些定期统计可以安排在夜间执行。


#### InnoDB锁问题
InnoDB与MyISAM 的最大不同有两点：一是支持事务（Transaction）;二是采用行级锁。
行级锁和表级锁本来就有许多不同之处，另外，事务的引入也带来一些问题。

#####  1、事务（transaction）及其ACID属性
	事务是由一组sql语句组成的逻辑处理单元，事务具有4个属性，通常称为事务的ACID属性。
*  原子性: 事务是一个原子操作单元，其对数据的修改，要么全部执行，要么全部不执行。
*  一致性：在事务开始和完成时，数据必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以 操持完整性；事务结束时，所有的内部数据结构（B树索引或者双向链表）也都是必须是正确的。
*  隔离性： 数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的独立环境执行，这意味着事务处理过程中的中间状态对外部是不可见的，反之依然。
*  持久性： 事务完成之后，他对于数据的修改是永久的，即出现系统故障也能保持。

#####  2、并发带来的问题
相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持更多的用户。但并发事务会带来一些问题，主要包括以下几种情况。

	*  更新丢失（lost update ）：当两个或者多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题---最后的更新覆盖了其他事务所做的更新。
	*  脏读（dirty reads）：A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作，这个时候如果B事务回滚，那么A事务读取到的数据是不被承认的。
	* 不可重复度（non-repeatable reads）：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读。也就是说，当前事务先进行了一次读取，然后再次读取带到的数据是别的事务修改后的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。
	* 幻读（Phantom reads）： 事务A 首先根据条件索引得到N条数据，然后事务B 改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+1条数据，这就产生了幻读。

	注：不可重复读与幻读的比较：
	两者有些相似，但是前者针对的是update 和delete,后者针对的是insert。
	区别：前者是指读到了已经提交的事务的更改数据（修改和删除），后者是指读到了其他已经提交的事务的新增数据。


#####  3、事务隔离级别 
    
    *  未提交读取：
    *  已提交读：
    *  可重复读：
    *  可序列化： 隔离级别最高	

mysql索引失效
===
索引失效条件：
1. 在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描
2. 存储引擎不能使用索引范围条件右边的列
3. 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select *
4. mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
5. is null,is not null也无法使用索引
6. like以通配符开头（’%abc…’）mysql索引失效会变成全表扫描的操作。

### mysql存储过程  

* delimiter 修改结束符
   1. 在MySQL中默认的结束符DELIMITER是; ，它用于标识一段命令是否结束。在默认情况下，在命令行客户端中，如果有一行命令以;结束，那么回车后，MySQL将会执行该命令。  
   
* 为什么修改结束符  
  1. 在创建函数需要写多条语句，此时如果用;分隔不同语句时就会导致直接执行目前所键入的命令，而创建函数或构建方法失败。  
  2. 一般将结束符替换为 $$  //   ;;  ,在函数创建之后，讲结束符修改为默认的 ；分号  

* mysql存储过程的常见和使用  
 
   1. 创建  
      1. 修改默认结束符 delimiter $$  
      2. create procedure  [存储过程名称] (in|out|inout 参数名 参数类型)  
         begin  
           业务语句
         end $$
      3. delimiter ;  //将结束符修改回来 
   2. 存储过程参数  
      1. 存储过程可以有0个或多个参数，用于存储过程的定义。  
      2. 三种类型 ：
          1. IN输入参数：表示调用者向过程传入值（传入值可以是字面量或变量）
             
          2. OUT输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量）
             
          3. INOUT输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量
   
     
* 调用存储过程： call sql_name[参数]

  1. 注意   
      1.  如果过程没有参数，也必须在过程名后面写上小括号
      　　　　例：CREATE PROCEDURE sp_name ([proc_parameter[,...]]) ……
      
      2. 确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理

#### [mybatis使用存储过程](https://blog.csdn.net/dwenxue/article/details/82257944)  

*  查询的过程调用  
    1. 查询的存储过程  
     CREATE PROCEDURE getUserById(IN u_id INTEGER)  
     BEGIN  
        SELECT id,name,sex,age FROM t_user WHERE id=u_id;  
     END  

* mapping 中如何调用   
``` 

   <!-- 根据id查询用户 -->
	<select id="getUserById" parameterType="Integer" resultType="user" statementType="CALLABLE">
		{call getUserById(#{id,mode=IN})}
	</select>
statementType 参数解释 ：
1、STATEMENT:直接操作sql，不进行预编译，获取数据：$—Statement 
2、PREPARED prepared:预处理，参数，进行预编译，获取数据：#—–PreparedStatement:默认 
3、CALLABLE:执行存储过程————CallableStatement 
```
####  DDL
1. DDL(Data Definition Language 数据定义语言)用于操作对象和对象的属性，这种对象包括数据库本身，以及数据库对象，像：表、视图等等，DDL对这些对象和属性的管理和定义具体表现在Create、Drop和Alter上。  
2. DDL的主要语句(操作)
   
   Create语句：可以创建数据库和数据库的一些对象。
   
   Drop语句：可以删除数据表、索引、触发程序、条件约束以及数据表的权限等。
   
   Alter语句：修改数据表定义及属性。
   
   DDL的操作对象(表)  

#### DML  
1. DML(Data Manipulation Language 数据操控语言)用于操作数据库对象中包含的数据，也就是说操作的单位是记录。  
2. DML的主要语句(操作)
   
   Insert语句：向数据表张插入一条记录。
   
   Delete语句：删除数据表中的一条或多条记录，也可以删除数据表中的所有记录，但是，它的操作对象仍是记录。
   
   Update语句：用于修改已存在表中的记录的内容。
   
   DML的操作对象——记录  
   注意     
   当我们对记录进行Insert、Delete和Update操作的时候，一定要注意，一定要清楚DDL对其的一些操作。

#### 分表 

* 

#### explain 

* explain 的作用  
 ```
 explain这个命令来查看一个这些SQL语句的执行计划,查看该SQL语句有没有使用上了索引

```

* expain出来的信息有10列，分别是id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra
```
概要描述：
id:选择标识符
我的理解是SQL执行的顺序的标识，SQL从大到小的执行
1. id相同时，执行顺序由上至下
2. 如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行

select_type:表示查询的类型。
(1) SIMPLE(简单SELECT，不使用UNION或子查询等)

(2) primary(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY)

(3) UNION(UNION中的第二个或后面的SELECT语句)

(4) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)

(5) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select)

(6) subquery(子查询中的第一个SELECT，结果不依赖于外部查询)

 


table:输出结果集的表
partitions:匹配的分区
type:表示表的连接类型  range:只检索给定范围的行，使用一个索引来选择行
possible_keys:表示查询时，可能使用的索引
key:表示实际使用的索引
key_len:索引字段的长度     长度越短越好 
ref:列与索引的比较
rows:扫描出的行数(估算的行数)
filtered:按表条件过滤的行百分比
Extra:执行情况的描述和说明
```

#### 索引分类  

索引（index）也叫做“键（key）”，它是存储引擎用于快速找到记录的一种数据结构。


* 主键索引（PRIMARY KEY）  
```
并提供唯一性约束。一张表中只能有一个主键。被标志为自动增长的字段一定是主键，但主键不一定是自动增长。一般把主键定义在无意义的字段上（如：编号），主键的数据类型最好是数值。
ADD PRIMARY KEY (`name`) USING BTREE;

```

* 全文索引（FULL TEXT）  

```
1. 新版的MySQL5.6.24上InnoDB引擎也加入了全文索引
2. ADD FULLTEXT INDEX `idx_full`(`en_name`);
3. 使用全文索引的格式： MATCH (columnName) AGAINST (‘string’)
```
* 常规索引(INDEX或KEY) 

```
1.单列索引
 ALTER TABLE `testDB`.`user` ADD INDEX `idx_name`(`name`) USING BTREE

2.组合索引最左前缀原则  


```

* 唯一索引（UNIQUE KEY）
```
ADD UNIQUE INDEX `idx_unique`(`en_name`);
1. 唯一性索引列允许空值，而主键列不允许为空值。
2. 一个表最多只能创建一个主键，但可以创建多个唯一索引。
3. 主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。
```  

* 索引的数据结构  








#### join 小表驱动大表  

```
1.可以使用被驱动表的索引
2.如果无法使用索引
小表做驱动表，大表做被驱动表
小表定义：在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。
情况一：两个表所有字段参与结果
select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;
select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;
join_buffer 只需要放入 t2 的前 50 行，显然是更好的。所以这里，“t2 的前 50 行”是那个相对小的表，也就是“小表”。
情况二：
select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;
这个例子里，表 t1 和 t2 都是只有 100 行参加 join。但是，这两条语句每次查询放入 join_buffer 中的数据是不一样的：
表 t1 只查字段 b，因此如果把 t1 放到 join_buffer 中，则 join_buffer 中只需要放入 b 的值；
表 t2 需要查所有的字段，因此如果把表 t2 放到 join_buffer 中的话，就需要放入三个字段 id、a 和 b。
这里，我们应该选择表 t1 作为驱动表。也就是说在这个例子里，“只需要一列参与 join 的表 t1”是那个相对小的表。
```

* sql执行顺序  
```
(8) SELECT (9)DISTINCT<select_list>
(1) FROM <left_table>
(3) <join_type> JOIN <right_table>
(2)         ON <join_condition>
(4) WHERE <where_condition>
(5) GROUP BY <group_by_list>
(6) WITH {CUBE|ROLLUP}
(7) HAVING <having_condition>
(10) ORDER BY <order_by_list>
(11) LIMIT <limit_number>

可以看到，一共有十一个步骤，最先执行的是FROM操作，最后执行的是LIMIT操作。每个操作都会产生一个虚拟表，该虚拟表作为一个处理的输入，看下执行顺序：

(1) FROM:对FROM子句中的左表<left_table>和右表<right_table>执行笛卡儿积，产生虚拟表VT1;
(2) ON: 对虚拟表VT1进行ON筛选，只有那些符合<join_condition>的行才被插入虚拟表VT2;
(3) JOIN: 如果指定了OUTER JOIN(如LEFT OUTER JOIN、RIGHT OUTER JOIN)，那么保留表中未匹配的行作为外部行添加到虚拟表VT2，产生虚拟表VT3。如果FROM子句包含两个以上的表，则对上一个连接生成的结果表VT3和下一个表重复执行步骤1~步骤3，直到处理完所有的表;
(4) WHERE: 对虚拟表VT3应用WHERE过滤条件，只有符合<where_condition>的记录才会被插入虚拟表VT4;
(5) GROUP By: 根据GROUP BY子句中的列，对VT4中的记录进行分组操作，产生VT5;
(6) CUBE|ROllUP: 对VT5进行CUBE或ROLLUP操作，产生表VT6;
(7) HAVING: 对虚拟表VT6应用HAVING过滤器，只有符合<having_condition>的记录才会被插入到VT7;
(8) SELECT: 第二次执行SELECT操作，选择指定的列，插入到虚拟表VT8中;
(9) DISTINCT: 去除重复，产生虚拟表VT9;
(10) ORDER BY: 将虚拟表VT9中的记录按照<order_by_list>进行排序操作，产生虚拟表VT10;
(11) LIMIT: 取出指定街行的记录，产生虚拟表VT11，并返回给查询用户

通过对执行顺序的理解，可以为我们未来的优化工作带来很大帮助。一个很浅显的认识就是，优化动作越靠前越好。
```
---
### 锁的分类

1. [mysql的共享锁和排它锁](https://blog.csdn.net/u014292162/article/details/83271299) 
   1. mysql中行级锁中的共享锁与排他锁进行分享交流 
   ```
   1. 共享锁又称为读锁，简称S锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。
        共享锁,就是多个事务只能读数据不能改数据
   
   2. 排他锁又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。
       排他锁指的是一个事务在一行数据加上排他锁后，其他事务不能再在其上加其他的锁;但是select语句默认不会加任何锁类型，即使加了排它锁也可以查询
   ```
    2. [锁的目的以及各种锁](https://zhuanlan.zhihu.com/p/52678870)
        ```
       1. 锁，当多个用户对数据库进行操作时，会带来数据不一致的情况，因此，锁主要是在多用户情况下保证数据库数据完整性和一致性。
       2. 锁的示意图 https://zhuanlan.zhihu.com/p/52678870
          1.行锁：行锁就是一锁锁一行或者多行记录，mysql的行锁是基于索引加载的，所以行锁是要加在索引响应的行上，即命中索引
              行锁查询：数据库表中有一个主键索引和一个普通索引，Sql语句基于普通索引查询，命中两条记录。此时行锁一锁就锁定两条记录，当其他事务访问数据库同一张表时，被锁定的记录不能被访问，其他的记录都可以访问到。
               行锁更新：
    
           2.表锁：表锁响应的是非索引字段，即全表扫描；表锁就是一锁锁一整张表，在表被锁定期间，其他事务不能对该表进行操作，必须等当前表的锁被释放后才能进行操作
              表锁更新：在窗口A中更新一条记录，条件为非索引字段，不提交事务，然后在窗口B中任意再更新一条记录，当更新数据库数据时，如果没有触发索引，则会锁表，锁表后再对表做任何变更操作都会导致锁冲突，所以表锁的锁冲突概率较高。
             
       3. mysql中，行锁又衍生了其他锁，分别是 记录锁、间隙锁、临键锁；我们依次来看看这三种锁，什么是记录锁呢？
       记录锁：记录锁锁的是表中的某一条记录，记录锁的出现条件必须是精准命中索引并且索引是唯一索引，如主键id
       间隙锁：间隙锁又称之为区间锁，每次锁定都是锁定一个区间；间隙锁的触发条件必然是命中索引的，当我们查询数据用范围查询而不是相等条件查询时，查询条件命中索引，并且没有查询到符合条件的记录
              
       ```
---
### [sql优化1](https://blog.csdn.net/qq_38789941/article/details/83744271) 
```
二、SQL优化的一些方法

1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。    
    
2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：    
select id from t where num is null    
可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：    
select id from t where num=0    
    
3.应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。    
    
4.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：    
select id from t where num=10 or num=20    
可以这样查询：    
select id from t where num=10    
union all    
select id from t where num=20    
    
5.in 和 not in 也要慎用，否则会导致全表扫描，如：    
select id from t where num in(1,2,3)    
对于连续的数值，能用 between 就不要用 in 了：    
select id from t where num between 1 and 3    
    
6.下面的查询也将导致全表扫描：    
select id from t where name like '%abc%'    
    
7.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：    
select id from t where num/2=100    
应改为:    
select id from t where num=100*2    
    
8.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：    
select id from t where substring(name,1,3)='abc'--name以abc开头的id    
应改为:    
select id from t where name like 'abc%'    
    
9.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。    
    
10.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。    
    
11.不要写一些没有意义的查询，如需要生成一个空表结构：    
select col1,col2 into #t from t where 1=0    
这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：    
create table #t(...)    
    
12.很多时候用 exists 代替 in 是一个好的选择：    
select num from a where num in(select num from b)    
用下面的语句替换：    
select num from a where exists(select 1 from b where num=a.num)    
    
13.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。    
    
14.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，    
因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。    
一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。    
    
15.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。    
这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。    
    
16.尽可能的使用 varchar 代替 char ，因为首先变长字段存储空间小，可以节省存储空间，    
其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。    
    
17.任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。    
    
18.避免频繁创建和删除临时表，以减少系统表资源的消耗。

19.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。    
    
20.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，    
以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。

21.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。    
    
22.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。    
    
23.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。

24.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。
在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。

25.尽量避免大事务操作，提高系统并发能力。

26.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。
```
---
### [sql优化2](https://blog.csdn.net/qq_38789941/article/details/83744271)

---
### 数据库优化之 IO cpu诊断

---
### 数据库分库分表

---
### 分表后如何做统计操作
---
### [Mysql数据库常用函数](https://www.cnblogs.com/progor/p/8832663.html)

```
字符串
concat(str1,str2,...strn)	连接str1，str2，...，strn为一个字符串
insert(str,x,y,instr)	将字符串str，从索引x开始，y个字符长度的子串替换为instr
substring(str,x,y)	返回从字符串str，索引x开始起y个字符长度的子串
replace(str,a,b)	用字符串b替换str中所有出现的字符串a
lower(str)	将str中的字符全转换为小写
upper(str)	将str中的字符全转换为大写

日期
sysdate()

（字符串转换为日期）函数：str_to_date(str, format)
select str_to_date('08/09/2008', '%m/%d/%Y'); -- 2008-08-09

为日期增加一个时间间隔：date_add()
set @dt = '2008-08-09 12:12:33';
select date_add(@dt, interval '01:15:30' hour_second);

DATE_ADD(date,INTERVAL expr type)
DATE_SUB(date,INTERVAL expr type)
其中date是指定的日期，INTERVAL为关键词，expr是具体的时间间隔，type是时间单位
```











































