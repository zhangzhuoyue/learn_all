面试的需要准备的内容
===

1、java基础

	a) .集合
		
	**所有涉及到集合删除元素的操作时,使用迭代器Iterator去完成**
	List集合：有序，可以重复的集合，三个典型实现：

	List list1 = new ArrayList()：底层数据结构是数组，查询快，增删慢；线程不安全，效率高
	List list2 = new LinkedList()：底层数据结构是链表，查询慢，增删快；线程不安全，效率高
	List list3 = new Vector()：底层数据结构是数组，查询快，增删慢；线程安全，效率低，几乎已经淘汰了这个集合

	**面试题2:ArrayList和LinkedList的区别？**
	1. 存储结构不同 ：ArrayList的实现是基于动态数组的数据结构，LinkList是基于链表的数据结构。
	2. 对于随机访问的（查询），ArrayList 的效率高于LinkList
	3. 对于新增和删除的操作，LinkList的效率较高。 
	
	ArrayList是利用数组完成的集合，取值的时候按存入的数据的先后取值，先进先出，第一个存入的数据下标为0，在0的基础上加值，LinkList利用堆栈完成集合，相比于ArrayList，它的存储值是倒过来的，先进后出，第一个存入的最后一个输出。
 
**面试题4：list与array的区别？**

	list是集合，array是数组，数组可以直接使用，list是接口,需要使用实现类，arraylist数组必须制定大小，list可以自己扩充大小。

**面试题5:怎样将一个数组转成List，有什么方法？**

** HashMap与Hashtable的区别 **
	 ### **HashTable**

		*   底层数组+链表实现，无论key还是value都**不能为null**，线程**安全**，实现线程安全的方式是在修改数据时锁住整个HashTable，效率低，ConcurrentHashMap做了相关优化
		*   初始size为**11**，扩容：newsize = olesize*2+1

	### **HashMap**

		*   底层数组+链表实现，可**以存储null键和null值**，线程**不安全**
		*   初始size为**16**，扩容：newsize = oldsize*2，size一定为2的n次幂
		*   扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入
		*   插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）
		*   当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀

	### **ConcurrentHashMap**

		*   底层采用分段的数组+链表实现，线程**安全**
		*   通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)
		*   Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术
		*   有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁
		*   扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容


**HashMap底层是如何实现的？**
首先底层数据结构是由数组+链表组成链表散列。HashMap先得到key的散列值，在通过扰动函数（减少碰撞次数）得到Hash值，接着通过hash & （n -1 ），n位table的长度，运算后得到数组的索引值。如果当前节点存在元素，则通过比较hash值和key值是否相等，相等则替换，不相等则通过拉链法查找元素，直到找到相等或者下个节点为null时。
1.8对扰动函数，扩容方法进行优化，并且增加了红黑树的数据结构。

**HashMap 和 Hashtable 的区别**
线程安全 HashMap是线程不安全的，而HashTable是线程安全的，每个人方法通过修饰synchronized来控制线程安全。
效率 HashMap比HashTable效率高，原因在于HashTable的方法通过synchronized修饰后，并发的效率会降低。
允不允许null HashMap运行只有一个key为null，可以有多个null的value。而HashTable不允许key，value为null。

3.HashMap的长度为什么是2的倍数
在HashMap的操作流程中，首先会对key进行hash算法得到一个索引值，这个索引值就是对应哈希桶数组的索引。为了得到这个索引值必须对扰动后的数跟数组长度进行取余运算。即 hash % n (n为hashmap的长度)，又因为&比%运算快。n如果为2的倍数，就可以将%转换为&，结果就是 hash & (n-1)。所以这就解释了为什么HashMap长度是2的倍数。

4.Jdk1.8中满足什么条件后将链表转化成红黑树？
很显然在putVal方法中是判断桶内的节点个数是否大于8，之后通过treeifyBin方法中判断长度是否大于最小红黑树容量64,小于则继续扩容，大于则转为红黑树。

	b) .多线程

	c) .io流

2、算法与数据结构

3、数据库相关的知识
	a) . 数据库mysql


	### mysql的知识点
本章节主要介绍Mysql架构，mysql 日志，mysql的mvcc,Mysql的索引，mysql语法，以及优化，执行计划和慢查询日志，主从备份，分布式事务等方面的体系化的讲述

##### Mysql的架构
  mysql分为server层和存储引擎

      server层
      * 连接器：管理连接权限验证
      * 查询缓存： 命中缓存直接换回查询结果
      * 分析器： 分析语法
      * 优化器： 生成执行计划，选择索引
      * 执行器： 操作索引返回结果

      存储引擎
        存储引擎负责数据的存储和提取，其架构是插件式，innodb sql 5.5.5版本开始成为mysql的默认存储引擎。

      各种引擎的对比：
        * innoDB ：支持事务，支持外键，InnoDB是聚焦索引，数据文件是和索引绑在一起的。必须要有主键，通过主键索引效率很高，但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据，不支持全文检索。
        * MyISAM: 不支持事务，不支持外键，MySAM是非聚焦索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的，查询效率上MyiSAM要高于InnoDB,因此做读写分离的时候一般选择用InnoDB做主机，MYISAM做从机。
        * Menmory: 有比较大的缺陷使用场景很少，文件数据都存储在内存中，如果mysqld 的进程发生异常，重启或者关闭机器数据就会消失。

      sql的执行过程

        第一步： 客户端连接上mysql数据库的连接器，连接器获取权限，维持管理连接；连接完成后如果你没有后续的指令这个连接就会处于空闲状态，如果太长时间不使用这个连接就会断开，这个空闲时间默认为8小时，由wait_timeout参数控制。

        第二步： 往mysql数据库发送一条sql,这个时候查询缓存开始工作，看看之前有没有执行过这个sql,如果有则直接返回缓存里的数据到客户端，只要对表执行过更新错作缓存都会失效，因此一些很少更新的数据表可考虑使用数据缓存，对频繁更新的表使用缓存反而弊大于利。使用缓存的方法如下sql,通过SQL_CACHE指定：
            select SQL_CACHE * from table  where xxx=xxx

        第三步： 当未命中缓存的时候，分析器开始工作，分析器判断你是select 还是update 还是insert ，分析你的语法是否正确

        第四步： 优化器根据你的表的索引和sql语句决定使用哪个索引，决定join的顺序

        第五步： 执行器执行sql ,调用存储引擎的接口，扫描遍历表或者插入更新数据。

#### mysql日志
  mysql有两个重要的日志，redolog和binlog,redolog是属于innodb的日志，binlog则属于server层的日志。下面介绍这两个日志的作用：当我们更新数据库数据的时候，这两个日志文件也会被更新，记录数据更新操作。

  redolog又称做重做日志，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录，它在数据库重启回复的时候被使用，innodb利用这个日志恢复到数据库宕机前的状态，以此来保证数据的完整性。redolog是物理日志，记录的是某个表的数据做了哪些修改，redolog是固定大小的，也就是说后面的日志会覆盖前面的日志。

  binlog又称作归档日志，它记录了对mysql数据库执行更改的所有操作，但是不包括select、show这类操作。binlog是逻辑日志，记录的是某个表执行了哪些操作。binlog是追加形式的写入日志，后面的日志不会被覆盖前面的日志。

  数据更新过程
      我们执行一个更新操作是这样的： 读取对应的数据到内存中，——>写redolog日志 ——>redolog状态为prepare ——>写入binlog日志 ——>提交事务 ——>redolog状态为commit,数据正式写入日志文件。我们发现redolog的提交的方式为两段式提交，这样做的目的是为了数据恢复的时候确保数据恢复的准确性。因为数据恢复是通过备份的binlog来完成的，索引确保redolog要和binlog一致。


#### mysql 的MVCC
  事务的隔离级别在此略过，在这里单单只介绍mysql实现事务隔离的原理 ————mvcc(多版本并发控制)。在学习mvcc之前需要介绍快照读和当前读。
      快照读就是一个select 语句，例如
        select * from table
        在Repeatableread（可重复读）事务隔离级别下，快照读的特点是获取当前数据库的快照数据，对所有的commit的数据都不可见，快照读不会对上锁。

      当前读 是对所读数据上悲观锁使其他当前读无法操作数据

          select .... lock in shark mode
          select ... for update
          insert
          update
          delete

          上述语句中，后面三个sql都是给数据库上排他锁（X锁），而第一个sql 是给数据库上共享锁（S锁）。X锁是一旦某个当前读到这个锁，其他当前读则没有对这个事务读写的权利，其他当前读会被阻塞住。而S锁是当一个当前读对某条数据上S锁，其他当前读可以对该条数据也上S锁，但不能上X锁，拿到S锁的当前读可以读到数据但不能改数据。


#### MVCC原理
  innodb 实现快照读和当前读悲观锁的技术就是mvcc，innoDB在插入一条数据的时候会在后面跟上两个隐藏列。这两个隐藏列，一个保存了这个行的创建时的系统版本号，一个保存的是行的删除系统版本号。每开始一个新的事务，系统版本号就会自动增长，事务开始时刻的系统版本号会作为事务的ID,innodb 更新一条数据是设置旧数据删除版本号，然后插入一条新的数据并设置创建版本号，然后删除旧数据。那怎么保证快照读到的是未commit的数据呢？两个条件
      1.innodb 只查找创建版本遭遇当前的事务版本的数据行，即，航的系统版本号小于或者等于事务的系统版本号，这样可以确保事务读取的行，要么再事务开始前已经存在的，要么是事务自身插入或者修改过的。
      2.行的删除版本，要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行，在事务开始前未被删除。只有符合上述两个条件记录， 才能作为禅村结果返回。

    而数据库锁也是通过比对版本号来决定是否阻塞某个事务。

#### Mysql 索引
  索引介绍：
  
      索引按数据结构可分为哈希表、有序数组、搜索树、跳表。
        * 哈希表适用于只有等值查询的场景。
        * 有序数组适合等值查询和范围查询的场景，但有序数组的索引的更新代价大，所以最好用于静态数据表。
        * 搜索树的搜索效率稳定，不会出现大幅波动，而且基于索引的顺序扫描时，也可以利用双向指针快速左右移动，效率非常高。
        * 跳表可以理解为优化的哈希索引。

      innodb 使用了B+ 数索引模型，而且是多叉树，虽然二叉树的是索引中效率最高的，但是索引需要写入磁盘，如果使用二叉树磁盘IO会变得很频繁。在innodb索引中分为主键索引（聚簇索引）和非主键索引（二级索引）。主键索引保存了该行数据的全部信息，二级索引保存了该行数据的主键；所以使用二级索引的时候会先查询出主键值，然后回表查询出数据。而使用主键索引则不需要回表。

      对二级索引而言可使用覆盖索引来优化sql,看下面的两条sql
      select * from  table where key =1;select id form table wehere key=1;

      key 是一个二级索引，第一条sql是先查出id,然后根据id 回表查询出真正的数据。而第二条数据查询索引后直接返回数据不需要回表。第二条sql索引key覆盖了我们的查询需求，称为覆盖索引。

      普通索引和唯一索引
          innodb是按数据也来读取数据的，当要读取一条数据时候是先将本页数据全部读到内存中，然后找到对应的数据，而不是直接读取，每页数据的默认大小为16KB.
          当一个数据页需要更新数据时，如果内存中有该数据页就直接更新，如果没有该数据页则在不影响数据一致性的前提下；更新操作先缓存到change buffer中，在下次查询需要访问这个数据页的时候再写入更新操作除了查询会将 change buffer 写入磁盘，后台线程也会定期将change buffer 写入磁盘。对于唯一索引来说所有的更新操作都要先判断这个操作是否为违反唯一性的约束，因此唯一索引的更新无法使用change buffer ,而普通索引则可以。唯一索引比普通索引更新多一个唯一性校验的过程。

      联合索引
          两个或者更多列上的索引被称为联合索引（或者符合索引）。联合索引可以减少索引的开销，以联合索引（a,b,c）为例子，建立这样的索引箱单余建立了索引 a,ab,abc三个索引，————mysql 从左到右的使用索引中的字段，一个查询可以只使用索引的一部分，但是只能是最左侧的部分，而且最左侧字段是常量引用时，索引就十分有效，这就是最左前缀原则。由最左前缀原则可知，组合索引是有顺序的，那么哪个索引放在最前面就比较有讲究，对于组合索引还有一个知识点
              索引下推，假设组合索引（a,b,c）如下sql，
                select * form  table where a=xxx and b = xxx
              这个sql 会进行两次筛选，第一次查出 a=xxx数据，再从a=xxx中查出b=xxx数据。使用索引下推和不使用索引下推的区别在于不使用索引下推会先查询出a=xxx 的数据的主键，然后根据查询出的主键回表查询出全部数据，再全数据查询出b=xxx 的数据，而索引下推的执行过程是先查出a=xxx的数据的主键，然后在这些主键上二次查询b=xxx 的主键，然后在回表

                索引下推的特点：
                  * innodb 引擎的表，索引下推只能用于二级索引
                  * 索引下推一般可用于所查询字段不全是联合索引的字段，查询条件为多条件查询且查询字句字段全是联合索引

                
     优化器与索引

      在索引建立之后，一条语句可能会命中多个索引，这是，酒柜交由优化器来选择合适的索引，优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。那么优化器是怎么去确认索引的呢？优化器会优先选择扫描行数最少的索引，同时还会结合使用使用临时表，是否排序等因素经进行综合判断。mysql 在开始执行sql 之前，并不知道满足这个条件的记录有多少个条，而只能根据统计信息来估计，而估计统计信息是通过数据采样得出来的。

      其他索引知识点

        有时候需要索引很长的字符列，这会让索引变得很大很慢还占内存。通常可以开始的部分字符作为索引，这就是前缀索引。这样可以大大节约索引空间，从而提高索引效率，但这样会降低索引的选择性。

      脏页对数据的影响
        当内存数据页和磁盘的数据不一致的时候我们称这个内存页为脏页，内存数据写入磁盘后数据一致，称为干净页。当要读入数据而数据库没有内存的时候，这个时候需要淘汰内存中的数据页——干净页可以直接淘汰掉，而脏页需要先刷入磁盘再淘汰。如果一个查询要淘汰的脏页太多会导致查询的时间变长。为了减少脏页对数据库性能影响，innodb 会控制脏页的比例和脏页刷新时机。


### Mysql 中的锁（表所、行锁）
锁是计算机协调多个进程或者纯线程并发访问某一资源的机制。在数据库表中，除 传统的计算资源（CPU、RAM、I/O）的争用外，数据也是一种供用用户共享的资源，如何保证数据的并发访问的一致性，有效性是所在有数据库必须要解决的的一个问题。锁冲冲突也是影响数据并发访问的性能的一个重要因素，

#### 概述
相对于其他数据库而言，mysql的锁的机制比较复杂，其最显著的特点是不同的存储引擎支持不同的锁机制。mysql可以大致归纳为以下三种：

		1.表级锁：开销小，加锁块，不会出现死锁；锁的粒度比较大，发生锁冲突的概率最高，并发度最低
		2.行级锁：开销大，加锁慢，会出现死锁；锁的粒度小 ，发生锁的冲突的概率最低，并发程度也是最高。
		3.页面锁：开销和加锁的时间介于表锁和行级锁的中间；会出现死锁，锁定粒度介于表锁和行锁之间，并发度一般。

以下是 三种存储引擎 MYISAM 与BDB、InnoDB的各自对行锁、页锁、表锁是否支持

		MYISAM 支持表锁，不支持 行锁与页面锁。
		BDB 支持页面锁，和表锁，不支持行锁。
		InnoDB 支持行锁和表锁，不支持页面锁。 

#### mysql 的存储引擎MYISAM 下表级锁的锁的
mysql的表级锁有两种模式：共享锁（Tabel Read Lock）和表独占锁（Table Write Lock）

		*	对MYISAM的读操作，不会阻塞其他用户对同一张表请求，但会阻塞对同一张表的写请求。
		*	对MYISAM 的写操作，则会阻塞其他用户对同一张表的的读和写操作。
		*	MYIASM 表的读操作和写操作之间，以及写操作之间是串行（注意两种关系）。

当一个线程获得对一个表的写锁之后只有持锁线程可以对表进行更行操作，其他线程的读、写操作都会等待，直到锁被释放为止。

## MYSQL不同存储引擎下的的锁模式介绍

####  1、MYISAM 的模式介绍（因为 MYISAM存储引擎只支持表级锁）
#####  1. 兼容性
	归纳总结：对MYISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一张表的写请求；对MYISAM表的写操作，则会阻塞其他用户对同一张表的的读写之间的请求；MYISAM表的读和写操作之间，以及写和写之间是串行的（当一线程获得对一张表的写锁之后，只有持有锁的线程可以对表进行操作。其他线程的读、写都会等待，直到当前持有锁的线程释放为止。）

#####  2. 如何加锁
MYISAM在执行查询语句时（select ）前，会自动给涉及的所有表加读锁，在执行更新操作（update、delete、insert）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要直接用 LOCK TABLE 命令给 MYISAM 表添加显式加锁，
给MYISAM表添加显式的锁一般是为了一定程度上模拟事务操作，实现对某一时间点多个表的一致性读取，例如：有一个订单表order ,其中一个还有一个订单明细表order_detail ，其中记录有订单每一个产品的金额小计subtotal,假设我们需要检查这两个表的金额合计是否相等，可能就要执行以下的语句。

	select sum(total) from order;
	select sum(subtotal) from order_detail;

这时，如果不嫌给这两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，order_detail 表已经发生了变化，因此，正确的写法应该是：

	LOCK tables order read local ,order_detail read local;
	select sum(total)from order
	select sum(subtatal) from order_detail
	补充说明：1.上面的例子在LOCK tables 是加了local 选项，其作用，就是在满足MYISAM表的并发插入条件情况下，允许其他用户在表尾插入记录，
	2.在用LOCK tables 给显式加表锁是时，必须同时取得所有涉及表的锁，并且mysql 表并发支持锁升级。也就是说在执行LOCK tables 后，只能访问显式加锁的这些表，不能访问未加锁的表，同时，如果加的锁是读锁，那么只能执行查询操作，而不能执行更新操作。其实在自动加锁的情况下也基本如此，mysql问题一次获得sql语句所需要的全部锁，这也正是MYISAM存储引擎下不会出现死锁的原因，

一个session使用LOCK tables 命令时，给表film_text加了锁，这个session 可以查询锁定表中的记录，但更新或访问其他表都会提示错误；同时，另外一个session 可以查询表中的记录，但更新就会出现锁等待。

##### 并发锁
concurrent_insert和local操作（此操作为MYISAM引擎专有，InnoDB无此功能）
上面说只要给表加了读锁，其他的session对该表的写操作将被阻塞，那么有没有办法让其他session也能往里面添加数据。这里我们可以使用local关键字，语法如下：local table 表名 read local。这样在当前表被加读锁的时候，可以让其他session往表里添加记录，但需要配合concurrent_insert全局变量使用。

在一定条件下，MYISAM页支持查询和操作的并发执行。
MYISAM存储引擎下，有一个系统变量concurent_insert ，专门用以控制其并发插入的行为，其值可以为 0、1、2
*  当concurrent_insert 设置为0 时，不允许并发插入。
*  当concurrent_insert 设置为1时，如果MYISAM 允许在一个读表的同时，另一个机型从表尾插入记录。这也是MYISAM默认的设置。如果表的中间没有被删除的行行为，MYISAM允许在一个进程读表的同时，另一线程从表尾插入记录，这也是myisam的默认设置。

#####  MYISAM的锁的调度
前面讲过，MYISAM 存储引擎的读和写操作是互斥，读操作之间是串行的。那么一个进程请求某个MYISAM表的读锁，通时零一个进程也请求同一张表的写锁，mysql如何处理呢？答案是写进程先获得锁。不仅如此，即使是读操作先获得锁等待的队列，写请求后到，写锁也会查到读请求之前，这是mysql认为写请求比一般的读请求重要。这也是myisam表不太适合用于大量更新操作的和查询操作的应用的原因，因为，大量的更新操作会造成查询操作很难得到锁，从而永远处于阻塞状体。这种情况有时候会变得很槽糕，幸好我们可以通过一些设置来调节MYISAM的调度行为。
		*  通过指定启动low-priority-updates,使得myisam引擎默认给予读请求一优先的权利。
		*  通过执行命令 set LOW_PRIORITY_UPDATES=1,使得连接发出的请求更新请求的优先级降低。
		* 通过指定INSERT、UPDATE、DELETE 语句的LOW_PRIORITY属性，降低语句的优先级。

虽然上面3种方法都是要么更新优先要么查询优先，但是还是可以用来解决查询相对重要的应用中，读锁等待严重的问题。
另外，mysql页提供一种折中的方法，，即给系统参数， max_write_lock_count 设置一个合适的值，当一个表的读锁达到这个值之后，mysql便暂时将写请求的优先级降低。给读进程一定获得锁的机会。

这里还要强调一点：一些需要长时间运行的查询操作，也会是写进程饿死，因此应用中应尽量避免出现长时间运行的查询操作，不要总想用一条select 来解决问题。因为这种看似巧妙的sql语句，往往比较复杂。执行时间较长，在可能的情况下，通过使用中间表等措施随sql 语句做一定的分解，使得每一步查询能在较短时间内完成，从而减少锁冲突，如果负载查询不可避免，应尽量安排在数据库表空闲时间段执行，比如一些定期统计可以安排在夜间执行。


#### InnoDB锁问题
InnoDB与MyISAM 的最大不同有两点：一是支持事务（Transaction）;二是采用行级锁。
行级锁和表级锁本来就有许多不同之处，另外，事务的引入也带来一些问题。

#####  1、事务（transaction）及其ACID属性
	事务是由一组sql语句组成的逻辑处理单元，事务具有4个属性，通常称为事务的ACID属性。
*  原子性: 事务是一个原子操作单元，其对数据的修改，要么全部执行，要么全部不执行。
*  一致性：在事务开始和完成时，数据必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以 操持完整性；事务结束时，所有的内部数据结构（B树索引或者双向链表）也都是必须是正确的。
*  隔离性： 数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的独立环境执行，这意味着事务处理过程中的中间状态对外部是不可见的，反之依然。
*  持久性： 事务完成之后，他对于数据的修改是永久的，即出现系统故障也能保持。

#####  2、并发带来的问题
相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持更多的用户。但并发事务会带来一些问题，主要包括以下几种情况。

	*  更新丢失（lost update ）：当两个或者多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题---最后的更新覆盖了其他事务所做的更新。
	*  脏读（dirty reads）：A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作，这个时候如果B事务回滚，那么A事务读取到的数据是不被承认的。
	* 不可重复度（non-repeatable reads）：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读。也就是说，当前事务先进行了一次读取，然后再次读取带到的数据是别的事务修改后的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。
	* 幻读（Phantom reads）： 事务A 首先根据条件索引得到N条数据，然后事务B 改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+1条数据，这就产生了幻读。

	注：不可重复读与幻读的比较：
	两者有些相似，但是前者针对的是update 和delete,后者针对的是insert。
	区别：前者是指读到了已经提交的事务的更改数据（修改和删除），后者是指读到了其他已经提交的事务的新增数据。


#####  3、事务隔离级别 
    
    *  未提交读取：
    *  已提交读：
    *  可重复读：
    *  可序列化： 隔离级别最高	

mysql索引失效
===
索引失效条件：
1. 在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描
2. 存储引擎不能使用索引范围条件右边的列
3. 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select *
4. mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
5. is null,is not null也无法使用索引
6. like以通配符开头（’%abc…’）mysql索引失效会变成全表扫描的操作。

 
4、nosql 非关系型数据库
	a) . reids
  1、数据类型：介绍
  2、redis的持久化方式：rdb、aof,以及他们之间的对比
  3、reids的集群方式，三种：着重了解哨兵的方式

	
		
	b) . mongodb
		

5、springboot+springclod
	
	1、aop 的实际使用案例
	2、springboot的启动原理
	3、filter+inercepter+监听器的区别
	4、
6、持久层框架
	a) .  Mybatis
	b) . jpa

7、tomcat的知识
	

8、搜索引擎
	a) . elasticsearch

9、消息中间件
	a) .  kafka+rabbitMQ

	1、使用MQ的作用
	2、rabbitmq的确保消息投递成功
	##### 
一、可靠性投递  分为7步 
* 第一步 ：首先把消息信息(业务数据) 存储到数据库表中，紧接着，我们再把这个消息记录也存到一张表中(或者另一个同源数据库的消息记录表).
* 第二步 ：发消息到RabbitMQ 的MQ Broker节点（采用confirm方式发送，会有异步的返回结果）。
 * 第三步、第四步 ：生产者端接收MQ Broker 节点返回的confirm确认消息结果，然后进行更新消息记录表状态，比如默认status=0 当收到消息确认消息成功后更新为1即可
 * 第五步 ：但是消息确认的这个过程可能存在网络闪断、MQ Broker端异常等原因导致，、会收消息失败、或者异常。这个时候就需要发送方(生产者) 对消息进行可靠性投递，保证消息不丢失，100%的投递成功，(有一种极限情况是闪断，Broker 返回的成功确认消息，但是由于生产端由于网络闪断没有收到，这时候重新投递可能造成 消息重复，需要消费端做幂等性处理)所以我们需要一个定时任务，（比如每5分钟拉取一下处理中间状态的消息，当然这个消息可以设置一个超时时间，比如超时1分钟 status = 0 ，也就是说明了12分钟这个时间窗口内，我们的消息没有确认，那么都会被定时任务拉去出来），
 * 第六步 ：接下来我们把中间状态的消息进行重新投递 retry send ，继续发送消息到MQ ,当然也可能有多种原因导致失败。
* 第七步 ：我们可以采用设置最大努力尝试次数，比如投递了3次，还是失败了，那我们可以将最终状态 status = 2 ,最后交由人工进行干预。

3、如何做到消息重复投递？

10、管理工具的使用【maven+git+svn】

11、Docker+k8s


